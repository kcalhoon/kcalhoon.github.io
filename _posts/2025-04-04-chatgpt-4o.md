---
title:  "Seeing is believing: examples of how new imaging LLMs change the game for better and worse"
date:   2025-04-04 12:30:16 -0700 (PDT)
categories: 
  - models
tags:
  - GPT-4o
  - image generation
---

Use cases for AI have felt elusive at times. Not so for the new autoregressive image making from OpenAI and Google. Getting specific imagery, including correctly written text, was once a total crapshoot. Not anymore.

<!--more-->

I've been reaching out to clients and colleagues with use cases. See the carousel below.

Some initial observations:

* Just like text, the LLMs are amazing but also make mistakes. The difference is that we can now iterate on specific issues, like spelling (see the digital ad example).
* Prompting strategies are important, just like text-LLM use, in getting what you want the first time. Also like text-LLMs, the technology will undoubtedly improve and require less prompting skill.
* Fraud will be an issue (see car example). Like with text, technologies will have to be developed to detect the LLM images or ensure photos are untouched. I can imagine insurance companies building in specific picture taking to ensure images are real.
* OpenAI has admitted their 'servers are melting.' A hack I've found is to check both the (iOS) app and the web site for the image rendering. Speed between them varies.

<div class="pdf-container" style="width: 100%; max-width: 960px;">
  <iframe 
    src="/assets/pdfs/image generation chatgpt-4o image.pdf#page=1&view=FitH&pagemode=thumbs" 
    width="100%" 
    height="700px" 
    style="border: 1px solid #ddd;"
  ></iframe>
</div>